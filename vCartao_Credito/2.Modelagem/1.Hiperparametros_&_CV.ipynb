{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivos\n",
    "\n",
    "Primeiro, algumas variáveis serão descartadas pelo acúmulo de importância (~90%) e pelo valor de IV.\n",
    "\n",
    "Segundo, com o uso da validação cruzada: será avaliado o comportamento médio de algumas métricas calculadas nos modelos baselines como a curva sobre a curva precision e recall (AUCPR), Brier Score (BS) e log-loss; foi visto que a identificação de um melhor ponto de corte pode melhorar a métrica F1-score. Dessa forma, será calculado qual o melhor ponto de corte médio.\n",
    "\n",
    "Terceiro, será escolhido qual o melhor conjunto de hiperparâmetros para os modelos Random Forest e XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deltalake import DeltaTable, write_deltalake\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import Funcoes\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score, average_precision_score, brier_score_loss, confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_recall_curve, log_loss\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, Trials, hp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura da base v1 e filtro de variáveis\n",
    "\n",
    "Variáveis com valor acumulado de importância em ~90% e pelo valor de IV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>vfm</th>\n",
       "      <th>pmcc</th>\n",
       "      <th>Income_Category_1.&lt; 40k</th>\n",
       "      <th>Income_Category_2. &gt;= 40k &amp; &lt; 60k</th>\n",
       "      <th>Income_Category_3. &gt;= 60k &amp; &lt; 80k</th>\n",
       "      <th>Income_Category_4. &gt;= 80k &amp; &lt; 120k</th>\n",
       "      <th>Income_Category_5. &gt;= 120k</th>\n",
       "      <th>Education_Level_v2_1.Uneducated</th>\n",
       "      <th>Education_Level_v2_2.High School</th>\n",
       "      <th>Education_Level_v2_3.Graduate</th>\n",
       "      <th>Education_Level_v2_4.Post-Graduate</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.784196</td>\n",
       "      <td>1.403132</td>\n",
       "      <td>-1.337898</td>\n",
       "      <td>0.498943</td>\n",
       "      <td>0.963894</td>\n",
       "      <td>0.282975</td>\n",
       "      <td>-0.328225</td>\n",
       "      <td>-0.175537</td>\n",
       "      <td>-0.421450</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Treino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.720070</td>\n",
       "      <td>-0.525933</td>\n",
       "      <td>0.641818</td>\n",
       "      <td>1.408428</td>\n",
       "      <td>-0.165769</td>\n",
       "      <td>-1.527806</td>\n",
       "      <td>-0.194304</td>\n",
       "      <td>-0.208685</td>\n",
       "      <td>-1.054789</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Treino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.346848</td>\n",
       "      <td>-0.525933</td>\n",
       "      <td>-0.348040</td>\n",
       "      <td>0.498943</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.894171</td>\n",
       "      <td>0.056797</td>\n",
       "      <td>-0.571459</td>\n",
       "      <td>-0.686436</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Treino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.218648</td>\n",
       "      <td>-0.525933</td>\n",
       "      <td>0.641818</td>\n",
       "      <td>-1.320028</td>\n",
       "      <td>-0.412731</td>\n",
       "      <td>0.369637</td>\n",
       "      <td>0.851953</td>\n",
       "      <td>0.252749</td>\n",
       "      <td>2.406712</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Treino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.539173</td>\n",
       "      <td>0.117089</td>\n",
       "      <td>1.631675</td>\n",
       "      <td>1.408428</td>\n",
       "      <td>-0.858972</td>\n",
       "      <td>0.346832</td>\n",
       "      <td>-1.144306</td>\n",
       "      <td>-0.064053</td>\n",
       "      <td>-0.071911</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Treino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Age  Total_Relationship_Count  Months_Inactive_12_mon  \\\n",
       "0     -0.784196                  1.403132               -1.337898   \n",
       "1      0.720070                 -0.525933                0.641818   \n",
       "2      1.346848                 -0.525933               -0.348040   \n",
       "3      0.218648                 -0.525933                0.641818   \n",
       "4     -2.539173                  0.117089                1.631675   \n",
       "\n",
       "   Contacts_Count_12_mon  Total_Revolving_Bal  Total_Amt_Chng_Q4_Q1  \\\n",
       "0               0.498943             0.963894              0.282975   \n",
       "1               1.408428            -0.165769             -1.527806   \n",
       "2               0.498943             0.864865              0.894171   \n",
       "3              -1.320028            -0.412731              0.369637   \n",
       "4               1.408428            -0.858972              0.346832   \n",
       "\n",
       "   Total_Ct_Chng_Q4_Q1       vfm      pmcc  Income_Category_1.< 40k  \\\n",
       "0            -0.328225 -0.175537 -0.421450                        1   \n",
       "1            -0.194304 -0.208685 -1.054789                        0   \n",
       "2             0.056797 -0.571459 -0.686436                        0   \n",
       "3             0.851953  0.252749  2.406712                        1   \n",
       "4            -1.144306 -0.064053 -0.071911                        1   \n",
       "\n",
       "   Income_Category_2. >= 40k & < 60k  Income_Category_3. >= 60k & < 80k  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  0   \n",
       "2                                  0                                  0   \n",
       "3                                  0                                  0   \n",
       "4                                  0                                  0   \n",
       "\n",
       "   Income_Category_4. >= 80k & < 120k  Income_Category_5. >= 120k  \\\n",
       "0                                   0                           0   \n",
       "1                                   1                           0   \n",
       "2                                   1                           0   \n",
       "3                                   0                           0   \n",
       "4                                   0                           0   \n",
       "\n",
       "   Education_Level_v2_1.Uneducated  Education_Level_v2_2.High School  \\\n",
       "0                                0                                 0   \n",
       "1                                0                                 0   \n",
       "2                                0                                 0   \n",
       "3                                0                                 0   \n",
       "4                                1                                 0   \n",
       "\n",
       "   Education_Level_v2_3.Graduate  Education_Level_v2_4.Post-Graduate  \\\n",
       "0                              1                                   0   \n",
       "1                              1                                   0   \n",
       "2                              0                                   1   \n",
       "3                              1                                   0   \n",
       "4                              0                                   0   \n",
       "\n",
       "   Attrition_Flag    type  \n",
       "0               0  Treino  \n",
       "1               0  Treino  \n",
       "2               0  Treino  \n",
       "3               0  Treino  \n",
       "4               0  Treino  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A chance de ser ou não churn não depende do sexo ser M ou F. Mas, ela pode ser uma proxy para comportamentos socioeconômicos como diferença de renda, ocupação em \n",
    "# atividades não remuneradas (múltiplas jornadas de trabalho) etc\n",
    "\n",
    "# Estado civil e número de dependentes podem ser interpretados de forma semelhante. Ambas podem direcionar para um maior compromisso com a estabilidade financeira,\n",
    "# pessoas com mais idade e, possivelmente, com principalidade de uso do cartão já definida.\n",
    "\n",
    "dados = DeltaTable(\"../1.Variaveis/tmp/dados_pp_v1\").to_pandas()\n",
    "dados.drop(['__index_level_0__', 'Card_Category_Gold', 'Card_Category_Platinum', 'Card_Category_Silver', \n",
    "            'Marital_Status_Married', 'Marital_Status_Single', 'Marital_Status_Unknown', 'Gender_M',\n",
    "            'Dependent_count'], axis=1, inplace=True)\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10127, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação das bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treino = dados[dados.type == 'Treino'].drop(['type'], axis=1)\n",
    "dados_val = dados[dados.type == 'Validacao'].drop(['type'], axis=1)\n",
    "dados_teste = dados[dados.type == 'Teste'].drop(['type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treino = dados_treino.drop(['Attrition_Flag'], axis=1)\n",
    "y_treino = dados_treino['Attrition_Flag']\n",
    "\n",
    "X_val = dados_val.drop(['Attrition_Flag'], axis=1)\n",
    "y_val = dados_val['Attrition_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Attrition_Flag\n",
       " 0    6140\n",
       " 1    1175\n",
       " Name: count, dtype: int64,\n",
       " Attrition_Flag\n",
       " 0    1084\n",
       " 1     208\n",
       " Name: count, dtype: int64,\n",
       " Attrition_Flag\n",
       " 0    1276\n",
       " 1     244\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treino.value_counts(), y_val.value_counts(), dados_teste['Attrition_Flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Será usado 5 folds de validação, para que a quantidade absoluta de churn seja equiparada a base de validação e teste (ver acima)\n",
    "1175/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação cruzada\n",
    "\n",
    "Para ter uma avaliação mais precisa dos modelos baselines, será usada a validação cruzada. É importante ter em mente que precisa-se de uma quantidade razoável da variável target para o estudo, além de se assemelhar com a proporção verdadeira na base completa (~16%).\n",
    "\n",
    "Para calcular os escores, das diferentes métricas, foi usado o cross_val_score (https://scikit-learn.org/1.5/modules/cross_validation.html).\n",
    "\n",
    "Para a escolha das métricas de estudo, pode-se escolher pela lista definida em 3.4.3.1 (https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção dos folds de forma estratificada para garantir a mesma representatividade da target\n",
    "\n",
    "SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=563)\n",
    "\n",
    "#  Instancia a Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(random_state=123)\n",
    "\n",
    "# Aplicação da validação cruzada e obtenção dos escores\n",
    "\n",
    "auc_pr_rf = cross_val_score(estimator=rf, X=X_treino, y=y_treino, cv=SKF, scoring='average_precision')\n",
    "bs_rf = cross_val_score(estimator=rf, X=X_treino, y=y_treino, cv=SKF, scoring='neg_brier_score')\n",
    "log_loss_rf = cross_val_score(estimator=rf, X=X_treino, y=y_treino, cv=SKF, scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No mlflow, os valores de AUCPR e BS na base de validação foram, respectivamente, 0.80 e 0.06. Comparado com o resultado médio das métricas abaixo, pode-se concluir que o modelo com os hiperparâmetros default está com performance boa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor médio de AUCPR: 0.8110720675084535\n",
      "Desvio padrão de AUCPR: 0.018858549324494565\n",
      "----------------------------------------\n",
      "Valor médio do BS: 0.06355405331510594\n",
      "Desvio padrão do BS: 0.0023251419277794854\n",
      "----------------------------------------\n",
      "Valor médio da log-loss: 0.23914582093998044\n",
      "Desvio padrão da log-loss: 0.017892713962885703\n"
     ]
    }
   ],
   "source": [
    "print('Valor médio de AUCPR:', auc_pr_rf.mean())\n",
    "print('Desvio padrão de AUCPR:', auc_pr_rf.std())\n",
    "\n",
    "print('----------------------------------------')\n",
    "\n",
    "print('Valor médio do BS:', bs_rf.mean()*(-1))\n",
    "print('Desvio padrão do BS:', bs_rf.std())\n",
    "\n",
    "print('----------------------------------------')\n",
    "\n",
    "print('Valor médio da log-loss:', log_loss_rf.mean()*(-1))\n",
    "print('Desvio padrão da log-loss:', log_loss_rf.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ao usar o XGBoost, as colunas não podem ter sinais de '>', '>=', '<' e '<='\n",
    "X_treino_new = X_treino.rename(columns={'Income_Category_1.< 40k': 'Income_Category_1.40k',\n",
    "                                        'Income_Category_2. >= 40k & < 60k': 'Income_Category_2.40k_60k',\n",
    "                                        'Income_Category_3. >= 60k & < 80k': 'Income_Category_3.60k_80k',\n",
    "                                        'Income_Category_4. >= 80k & < 120k': 'Income_Category_4.80k_120k',\n",
    "                                        'Income_Category_5. >= 120k': 'Income_Category_5.120k'\n",
    "                                        })\n",
    "\n",
    "X_val_new = X_val.rename(columns={'Income_Category_1.< 40k': 'Income_Category_1.40k',\n",
    "                                        'Income_Category_2. >= 40k & < 60k': 'Income_Category_2.40k_60k',\n",
    "                                        'Income_Category_3. >= 60k & < 80k': 'Income_Category_3.60k_80k',\n",
    "                                        'Income_Category_4. >= 80k & < 120k': 'Income_Category_4.80k_120k',\n",
    "                                        'Income_Category_5. >= 120k': 'Income_Category_5.120k'\n",
    "                                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção dos folds de forma estratificada para garantir a mesma representatividade da target\n",
    "\n",
    "SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=563)\n",
    "\n",
    "#  Instancia a XGBoost\n",
    "\n",
    "XGB = xgb.XGBClassifier(random_state=123)\n",
    "\n",
    "# Aplicação da validação cruzada e obtenção dos escores\n",
    "\n",
    "auc_pr_XGB = cross_val_score(estimator=XGB, X=X_treino_new, y=y_treino, cv=SKF, scoring='average_precision')\n",
    "bs_XGB = cross_val_score(estimator=XGB, X=X_treino_new, y=y_treino, cv=SKF, scoring='neg_brier_score')\n",
    "log_loss_XGB = cross_val_score(estimator=XGB, X=X_treino_new, y=y_treino, cv=SKF, scoring='neg_log_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No mlflow, os valores de AUCPR e BS na base de validação foram, respectivamente, 0.85 e 0.05. Comparado com o resultado médio das métricas abaixo, pode-se concluir que o modelo com os hiperparâmetros default está com performance boa.\n",
    "\n",
    "Em média os valores das métricas são melhores para o XGB, entretanto perdem um pouco em relação à variância que é um pouco maior (trade-off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor médio de AUCPR: 0.827286855808228\n",
      "Desvio padrão de AUCPR: 0.01765843965399739\n",
      "----------------------------------------\n",
      "Valor médio do BS: 0.059690328309613225\n",
      "Desvio padrão do BS: 0.004629364361334095\n",
      "----------------------------------------\n",
      "Valor médio da log-loss: 0.21693788939008582\n",
      "Desvio padrão da log-loss: 0.01650408191605959\n"
     ]
    }
   ],
   "source": [
    "print('Valor médio de AUCPR:', auc_pr_XGB.mean())\n",
    "print('Desvio padrão de AUCPR:', auc_pr_XGB.std())\n",
    "\n",
    "print('----------------------------------------')\n",
    "\n",
    "print('Valor médio do BS:', bs_XGB.mean()*(-1))\n",
    "print('Desvio padrão do BS:', bs_XGB.std())\n",
    "\n",
    "print('----------------------------------------')\n",
    "\n",
    "print('Valor médio da log-loss:', log_loss_XGB.mean()*(-1))\n",
    "print('Desvio padrão da log-loss:', log_loss_XGB.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do melhor ponto de corte médio com Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n"
     ]
    }
   ],
   "source": [
    "pontos_rf = []\n",
    "f1_rf = []\n",
    "\n",
    "for i, (treino_index, teste_index) in enumerate(SKF.split(X_treino, y_treino)):\n",
    "    \n",
    "    # Marcação do fold\n",
    "    \n",
    "    print(f\"Fold {i}\")\n",
    "    \n",
    "    # Divisão das bases de treino e teste\n",
    "    \n",
    "    X_treino_aux, X_teste_aux = X_treino.iloc[treino_index,:], X_treino.iloc[teste_index, :]\n",
    "    y_treino_aux, y_teste_aux = y_treino[treino_index], y_treino[teste_index]\n",
    "\n",
    "    # Aplicação da RF\n",
    "    \n",
    "    rf.fit(X_treino_aux, y_treino_aux)\n",
    "\n",
    "    # Avaliação do melhor ponto de corte com o uso da base de validação\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_teste_aux, rf.predict_proba(X_teste_aux)[:,1])\n",
    "\n",
    "    # Melhor threshold que fornece o melhor f1-score (média harmônica entre precisão (Positive Predicted Value ou PPV) e recall (TPR))\n",
    "\n",
    "    f1_scores = 2 * (precision*recall) / (precision + recall)\n",
    "    best_threshold_index = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_threshold_index]\n",
    "    best_f1 = f1_scores[best_threshold_index]\n",
    "    \n",
    "    pontos_rf.append(best_threshold)\n",
    "    f1_rf.append(best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em média, o melhor ponto de corte é 0.356, garantindo em média um f1-score de 0.747. No mlflow, observa-se que a métrica f1-score na base de validação ficou em aproximadamente 0.686 (com o uso do ponto de corte default em 0.5), ou seja, é possível ter um ganho com a otimização do ponto de corte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([np.float64(0.37),\n",
       "  np.float64(0.34),\n",
       "  np.float64(0.41),\n",
       "  np.float64(0.33),\n",
       "  np.float64(0.33)],\n",
       " [np.float64(0.726086956521739),\n",
       "  np.float64(0.7695560253699788),\n",
       "  np.float64(0.7527839643652562),\n",
       "  np.float64(0.7418032786885246),\n",
       "  np.float64(0.7479674796747968)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pontos_rf, f1_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.356),\n",
       " np.float64(0.03072458299147442),\n",
       " np.float64(0.747639540924059))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pontos_rf), np.std(pontos_rf), np.mean(f1_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do melhor ponto de corte médio com XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n"
     ]
    }
   ],
   "source": [
    "pontos_XGB = []\n",
    "f1_XGB = []\n",
    "\n",
    "for i, (treino_index, teste_index) in enumerate(SKF.split(X_treino_new, y_treino)):\n",
    "    \n",
    "    # Marcação do fold\n",
    "    \n",
    "    print(f\"Fold {i}\")\n",
    "    \n",
    "    # Divisão das bases de treino e teste\n",
    "    \n",
    "    X_treino_aux, X_teste_aux = X_treino_new.iloc[treino_index,:], X_treino_new.iloc[teste_index, :]\n",
    "    y_treino_aux, y_teste_aux = y_treino[treino_index], y_treino[teste_index]\n",
    "\n",
    "    # Aplicação da RF\n",
    "    \n",
    "    XGB.fit(X_treino_aux, y_treino_aux)\n",
    "\n",
    "    # Avaliação do melhor ponto de corte com o uso da base de validação\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_teste_aux, XGB.predict_proba(X_teste_aux)[:,1])\n",
    "\n",
    "    # Melhor threshold que fornece o melhor f1-score (média harmônica entre precisão (Positive Predicted Value ou PPV) e recall (TPR))\n",
    "\n",
    "    f1_scores = 2 * (precision*recall) / (precision + recall)\n",
    "    best_threshold_index = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[best_threshold_index]\n",
    "    best_f1 = f1_scores[best_threshold_index]\n",
    "    \n",
    "    pontos_XGB.append(best_threshold)\n",
    "    f1_XGB.append(best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em média, o melhor ponto de corte é 0.369, garantindo em média um f1-score de 0.755. No mlflow, observa-se que a métrica f1-score na base de validação ficou em aproximadamente 0.755 (com o uso do ponto de corte default em 0.5), ou seja, não houve alteração nessa métrica.\n",
    "\n",
    "Note que a variabilidade (desvio padrão) dos pontos de corte é maior comparado com o modelo Random Forest. Além disso, o ponto de corte médio para a RF é bem próximo do ponto de corte médio do XGBoost e os dois modelos possuem f1-score médio próximos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([np.float32(0.43493217),\n",
       "  np.float32(0.30468673),\n",
       "  np.float32(0.25663266),\n",
       "  np.float32(0.3706298),\n",
       "  np.float32(0.48277158)],\n",
       " [np.float64(0.7175925925925927),\n",
       "  np.float64(0.7748917748917749),\n",
       "  np.float64(0.7505154639175258),\n",
       "  np.float64(0.7583148558758315),\n",
       "  np.float64(0.7770114942528736)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pontos_XGB, f1_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(0.3699306),\n",
       " np.float32(0.082525104),\n",
       " np.float64(0.7556652363061197))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pontos_XGB), np.std(pontos_XGB), np.mean(f1_XGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão 1\n",
    "\n",
    "Dos resultados anteriores, percebe-se que a diferença é pequena (e praticamente desprezível) entre as métricas médias dos modelos ajustados. Dessa forma, PODE-SE optar por um modelo mais simples como é o caso da RF. Abaixo, será feita a procura de um melhor conjunto de hiperparâmetros para a RF e para o XGBoost.\n",
    "\n",
    "Como forma de recapitular conceitos chaves, o modelo RF faz parte dos métodos de bagging. Neste grupo, as principais características são: possibilidade de execução dos algoritmos de forma paralela e/ou distribuída; redução de variância e menor sensibilidade a overfitting.\n",
    "\n",
    "O modelo XGBoost faz parte dos métodos de boosting, com as seguintes características: a execução dos algoritmos é feita de forma sequencial, com enfoque em melhorar as predições nos grupos em que há mais erros e assim não pode ser executado de forma paralela e/ou distribuída; redução de viés e sensibilidade a overfitting (uma vez que o foco está nas observações com as piores predições)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajuste de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Attrition_Flag\n",
       " 0    3684\n",
       " 1     705\n",
       " Name: count, dtype: int64,\n",
       " Attrition_Flag\n",
       " 0    2456\n",
       " 1     470\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treino2, X_teste2, y_treino2, y_teste2 = train_test_split(X_treino_new, y_treino, test_size=.40, stratify=y_treino, random_state=1234)\n",
    "y_treino2.value_counts(), y_teste2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode ser que em alguma etapa de seleção de hiperparâmetros, algumas métricas não sejam bem definidas como precisão e recall, pois as medidas de falso positivo e verdadeiro positivo são iguais a zero ou falso negativo e verdadeiro positivo são iguais a zero. Assim, essas métricas foram desconsideras na função objetivo e mapeadas somente no final, na base de validação final.\n",
    "\n",
    "Abaixo, a função objetivo tem como alvo minimizar a função log-loss e utiliza-se a otimização bayesiana para alcançar o melhor conjunto de hiperparâmetros (https://hyperopt.github.io/hyperopt/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função objetivo sem a validação cruzada\n",
    "\n",
    "def func_objetivo(parametros, expr, modelo, X_treino, X_teste, y_treino, y_teste):\n",
    "    # função objetivo para \"minimizar\", mas dependendo da métrica de interesse, na realidade, é maximizar \n",
    "    # parâmetros é o espaço paramétrico a ser explorado\n",
    "    # expr é uma string que representa o id do experimento que foi criado\n",
    "    # modelo é uma string de qual modelo será rodado: Random Forest ou XGBoost\n",
    "    # X_treino, X_teste, y_treino, y_teste são as bases de treino e teste \n",
    "\n",
    "    # O output é o valor do score a ser minimizado/maximizado\n",
    "    \n",
    "    with mlflow.start_run(nested = True, experiment_id=expr) as run:\n",
    "\n",
    "        if modelo == 'RF':\n",
    "            clf = RandomForestClassifier(**parametros) \n",
    "            clf.fit(X_treino, y_treino)\n",
    "        elif modelo == 'XGB':\n",
    "            clf = xgb.XGBClassifier(**parametros)\n",
    "            clf.fit(X_treino, y_treino)\n",
    "        \n",
    "        #score = log_loss(y_teste, clf.predict_proba(X_teste)[:,1], normalize=False)\n",
    "        score = log_loss(y_teste, clf.predict_proba(X_teste)[:,1], normalize=True)\n",
    "\n",
    "        # Log de parâmetros e métricas \n",
    "\n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('log_loss_val', score)\n",
    "        mlflow.log_metric('aucpr_val', average_precision_score(y_teste, clf.predict_proba(X_teste)[:,1]))\n",
    "        mlflow.log_metric('roc_auc_score_val', roc_auc_score(y_teste, clf.predict_proba(X_teste)[:,1]))\n",
    "        #mlflow.log_metric('f1_score_val', f1_score(y_teste, clf.predict(X_teste)))\n",
    "        #mlflow.log_metric('precision_score_val', precision_score(y_teste, clf.predict(X_teste)))\n",
    "        #mlflow.log_metric('recall_score_val', recall_score(y_teste, clf.predict(X_teste)))\n",
    "        \n",
    "        signature = infer_signature(X_treino, clf.predict_proba(X_treino))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "# Função objetivo com validação cruzada\n",
    "# A otimização será feita considerando o comportamento médio da log-loss nos folds de validação\n",
    "\n",
    "def func_objetivo_CV(parametros, modelo, folds, expr, X, y):\n",
    "    # função objetivo para \"minimizar\", mas dependendo da métrica de interesse, na realidade, é maximizar \n",
    "    # parametros é o espaço paramétrico a ser explorado\n",
    "    # expr é uma string que representa o id do experimento que foi criado\n",
    "    # modelo é uma string de qual modelo será rodado: Random Forest ou XGBoost\n",
    "    # folds é um int que diz quantos folds de validação serão usados\n",
    "    # X e y são as bases que serão aplicadas o cross-validation\n",
    "\n",
    "    # O output é o valor do score a ser minimizado/maximizado\n",
    "    \n",
    "    with mlflow.start_run(nested = True, experiment_id=expr) as run:\n",
    "\n",
    "        SKF = StratifiedKFold(n_splits = folds, shuffle=True, random_state=1234)\n",
    "\n",
    "        if modelo == 'RF':\n",
    "            clf = RandomForestClassifier(**parametros) \n",
    "            clf.fit(X, y)\n",
    "        elif modelo == 'XGB':\n",
    "            clf = xgb.XGBClassifier(**parametros)\n",
    "            clf.fit(X, y)\n",
    "        \n",
    "        #score = cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='average_precision').mean()\n",
    "        score = cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='neg_log_loss').mean()\n",
    "\n",
    "        # Log de parâmetros e métricas\n",
    "\n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('average_precision_cv', cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='average_precision').mean())\n",
    "        mlflow.log_metric('roc_auc_cv', cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='roc_auc').mean())\n",
    "        mlflow.log_metric('neg_brier_score_cv', cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='neg_brier_score').mean())\n",
    "        mlflow.log_metric('neg_log_loss_cv', cross_val_score(estimator = clf, X = X, y = y, cv = SKF, scoring='neg_log_loss').mean())\n",
    "        \n",
    "        signature = infer_signature(X, clf.predict_proba(X))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')\n",
    "\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment = mlflow.create_experiment(name = 'Modelos_Tunados',\n",
    "#                                      artifact_location = 'Artf_Modelos_Tunados',\n",
    "#                                      tags = {'Environment': 'Development', 'Version': '2.0.0'}\n",
    "#                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'840998848624696013'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.set_experiment(experiment_id='840998848624696013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'840998848624696013'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de hiperparâmetros sem validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espaço hiperparamétrico com 6 dimensões: quantidade de árvores, profundidade máxima, quantidade mínima de observações na folha, quantidade mínima de amostras para divisão do nó, critério para a divisão do nó e o peso atribuído as amostras devido ao desbalanceamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:04<01:37,  4.07s/trial, best loss: 0.5243437337037734]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:08<01:34,  4.12s/trial, best loss: 0.3383480247955717]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:13<01:36,  4.37s/trial, best loss: 0.3383480247955717]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    #test_imbalanced = [{0: len(y_treino2)/(2*np.bincount(y_treino2))[0], 1:len(y_teste2)/(2*np.bincount(y_teste2))[1]}, {0: 1, 1:1}]\n",
    "    \n",
    "    space = {\n",
    "        \"n_estimators\": hp.choice('n_estimators', np.arange(10, 500, dtype=int)),\n",
    "        \"max_depth\": hp.choice('max_depth', np.arange(10, 300, dtype=int)),\n",
    "        \"min_samples_leaf\": hp.choice('min_samples_leaf', np.arange(200, 500, dtype=int)),\n",
    "        \"min_samples_split\": hp.choice('min_samples_split', np.arange(200, 500, dtype=int)),\n",
    "        \"criterion\": hp.choice(\"criterion\", ['gini', 'entropy', 'log_loss']),\n",
    "        \"class_weight\": hp.choice(\"class_weight\", ['balanced', 'balanced_subsample', None]) \n",
    "    }\n",
    "    \n",
    "    with mlflow.start_run(run_name = 'Random_Forest1', experiment_id=experiment.experiment_id) as run:\n",
    "        best_params = fmin(\n",
    "            fn = partial(\n",
    "                func_objetivo,\n",
    "                expr = experiment.experiment_id,\n",
    "                modelo = 'RF',\n",
    "                X_treino = X_treino2,\n",
    "                X_teste = X_teste2,\n",
    "                y_treino = y_treino2,\n",
    "                y_teste = y_teste2\n",
    "            ),\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 25,\n",
    "            trials = Trials(),\n",
    "            timeout = 10\n",
    "        )\n",
    "\n",
    "        if best_params['criterion'] == 0:\n",
    "            best_params['criterion'] = 'gini'\n",
    "        elif best_params['criterion'] == 1:\n",
    "            best_params['criterion'] = 'entropy'\n",
    "        else:\n",
    "            best_params['criterion'] = 'log_loss'\n",
    "            \n",
    "\n",
    "        if best_params['class_weight'] == 0:\n",
    "            best_params['class_weight'] = 'balanced'\n",
    "        elif best_params['class_weight'] == 1:\n",
    "            best_params['class_weight'] = 'balanced_subsample'\n",
    "        else:\n",
    "            best_params['class_weight'] = None\n",
    "        \n",
    "        # Identificado o melhor conjunto de hiperparâmetros, treina o modelo com toda a base de treino e metrifica os escores na base de validação\n",
    "\n",
    "        clf = RandomForestClassifier(**best_params)\n",
    "        clf.fit(X_treino_new, y_treino)\n",
    "                   \n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('aucpr_val', average_precision_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('log_loss_val', log_loss(y_val, clf.predict_proba(X_val_new)[:,1], normalize=True))\n",
    "        mlflow.log_metric('roc_auc_score_val', roc_auc_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('f1_score_val', f1_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('f1_score_val2', f1_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('precision_score_val', precision_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('precision_score_val2', precision_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('recall_score_val', recall_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('recall_score_val2', recall_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('brier_score', brier_score_loss(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "\n",
    "        signature = infer_signature(X_treino_new, clf.predict_proba(X_treino_new))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espaço hiperparamétrico com 2 dimensões, para alterar o menos possível os hiperparâmetros default, com os quais já se havia encontrado bons resultados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:03<01:33,  3.91s/trial, best loss: 0.2952681827606543]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:11<02:14,  5.87s/trial, best loss: 0.2254783429168717]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    #test_imbalanced = [{0: len(y_treino2)/(2*np.bincount(y_treino2))[0], 1:len(y_teste2)/(2*np.bincount(y_teste2))[1]}, {0: 1, 1:1}]\n",
    "    \n",
    "    space = {\n",
    "        \"n_estimators\": hp.choice('n_estimators', np.arange(10, 500, dtype=int)),\n",
    "        \"max_depth\": hp.choice('max_depth', np.arange(10, 300, dtype=int))\n",
    "    }\n",
    "    \n",
    "    with mlflow.start_run(run_name = 'Random_Forest2', experiment_id=experiment.experiment_id) as run:\n",
    "        best_params = fmin(\n",
    "            fn = partial(\n",
    "                func_objetivo,\n",
    "                expr = experiment.experiment_id,\n",
    "                modelo = 'RF',\n",
    "                X_treino = X_treino2,\n",
    "                X_teste = X_teste2,\n",
    "                y_treino = y_treino2,\n",
    "                y_teste = y_teste2\n",
    "            ),\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 25,\n",
    "            trials = Trials(),\n",
    "            timeout = 10\n",
    "        )\n",
    "       \n",
    "        # Identificado o melhor conjunto de hiperparâmetros, treina o modelo com toda a base de treino e metrifica os escores na base de validação\n",
    "\n",
    "        clf = RandomForestClassifier(**best_params)\n",
    "        clf.fit(X_treino_new, y_treino)\n",
    "                   \n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('aucpr_val', average_precision_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('log_loss_val', log_loss(y_val, clf.predict_proba(X_val_new)[:,1], normalize=True))\n",
    "        mlflow.log_metric('roc_auc_score_val', roc_auc_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('f1_score_val', f1_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('f1_score_val2', f1_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('precision_score_val', precision_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('precision_score_val2', precision_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('recall_score_val', recall_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('recall_score_val2', recall_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('brier_score', brier_score_loss(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "\n",
    "\n",
    "        signature = infer_signature(X_treino_new, clf.predict_proba(X_treino_new))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de hiperparâmetros com validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:10<04:10, 10.45s/trial, best loss: 0.49348483924992664]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    space = {\n",
    "        \"n_estimators\": hp.choice('n_estimators', np.arange(10, 500, dtype=int)),\n",
    "        \"max_depth\": hp.choice('max_depth', np.arange(10, 300, dtype=int)),\n",
    "        \"min_samples_leaf\": hp.choice('min_samples_leaf', np.arange(200, 500, dtype=int)),\n",
    "        \"min_samples_split\": hp.choice('min_samples_split', np.arange(200, 500, dtype=int)),\n",
    "        \"criterion\": hp.choice(\"criterion\", ['gini', 'entropy', 'log_loss']),\n",
    "        \"class_weight\": hp.choice(\"class_weight\", ['balanced', 'balanced_subsample', None]) \n",
    "    }\n",
    "    \n",
    "    with mlflow.start_run(run_name = 'Random_Forest_CV1', experiment_id=experiment.experiment_id) as run:\n",
    "        best_params = fmin(\n",
    "            fn = partial(\n",
    "                func_objetivo_CV,\n",
    "                expr = experiment.experiment_id,\n",
    "                modelo = 'RF',\n",
    "                X = X_treino_new,\n",
    "                y = y_treino,\n",
    "                folds = 5\n",
    "            ),\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 25,\n",
    "            trials = Trials(),\n",
    "            timeout = 10\n",
    "        )\n",
    "\n",
    "        if best_params['criterion'] == 0:\n",
    "            best_params['criterion'] = 'gini'\n",
    "        elif best_params['criterion'] == 1:\n",
    "            best_params['criterion'] = 'entropy'\n",
    "        else:\n",
    "            best_params['criterion'] = 'log_loss'\n",
    "            \n",
    "\n",
    "        if best_params['class_weight'] == 0:\n",
    "            best_params['class_weight'] = 'balanced'\n",
    "        elif best_params['class_weight'] == 1:\n",
    "            best_params['class_weight'] = 'balanced_subsample'\n",
    "        else:\n",
    "            best_params['class_weight'] = None\n",
    "        \n",
    "        # Identificado o melhor conjunto de hiperparâmetros, treina o modelo com toda a base de treino e metrifica os escores na base de validação\n",
    "\n",
    "        clf = RandomForestClassifier(**best_params)\n",
    "        clf.fit(X_treino_new, y_treino)\n",
    "                   \n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('aucpr_val', average_precision_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('log_loss_val', log_loss(y_val, clf.predict_proba(X_val_new)[:,1], normalize=True))\n",
    "        mlflow.log_metric('roc_auc_score_val', roc_auc_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('f1_score_val', f1_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('f1_score_val2', f1_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('precision_score_val', precision_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('precision_score_val2', precision_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('recall_score_val', recall_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('recall_score_val2', recall_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('brier_score', brier_score_loss(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "\n",
    "        signature = infer_signature(X_treino_new, clf.predict_proba(X_treino_new))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:17<07:08, 17.86s/trial, best loss: 0.27413191438820855]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    space = {\n",
    "        \"n_estimators\": hp.choice('n_estimators', np.arange(10, 500, dtype=int)),\n",
    "        \"max_depth\": hp.choice('max_depth', np.arange(10, 300, dtype=int))\n",
    "    }\n",
    "    \n",
    "    with mlflow.start_run(run_name = 'Random_Forest_CV2', experiment_id=experiment.experiment_id) as run:\n",
    "        best_params = fmin(\n",
    "            fn = partial(\n",
    "                func_objetivo_CV,\n",
    "                expr = experiment.experiment_id,\n",
    "                modelo = 'RF',\n",
    "                X = X_treino_new,\n",
    "                y = y_treino,\n",
    "                folds = 5\n",
    "            ),\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 25,\n",
    "            trials = Trials(),\n",
    "            timeout = 10\n",
    "        )\n",
    "\n",
    "       \n",
    "        # Identificado o melhor conjunto de hiperparâmetros, treina o modelo com toda a base de treino e metrifica os escores na base de validação\n",
    "\n",
    "        clf = RandomForestClassifier(**best_params)\n",
    "        clf.fit(X_treino_new, y_treino)\n",
    "                   \n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('aucpr_val', average_precision_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('log_loss_val', log_loss(y_val, clf.predict_proba(X_val_new)[:,1], normalize=True))\n",
    "        mlflow.log_metric('roc_auc_score_val', roc_auc_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('f1_score_val', f1_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('f1_score_val2', f1_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('precision_score_val', precision_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('precision_score_val2', precision_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('recall_score_val', recall_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('recall_score_val2', recall_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('brier_score', brier_score_loss(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "\n",
    "        signature = infer_signature(X_treino_new, clf.predict_proba(X_treino_new))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação com o RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
       "                   estimator=RandomForestClassifier(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [200, 250, 300, 350,\n",
       "                                                             400, 450, 500, 550,\n",
       "                                                             600],\n",
       "                                        &#x27;min_samples_split&#x27;: [200, 250, 300,\n",
       "                                                              350, 400, 450,\n",
       "                                                              500],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800]},\n",
       "                   return_train_score=True, scoring=&#x27;average_precision&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
       "                   estimator=RandomForestClassifier(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [200, 250, 300, 350,\n",
       "                                                             400, 450, 500, 550,\n",
       "                                                             600],\n",
       "                                        &#x27;min_samples_split&#x27;: [200, 250, 300,\n",
       "                                                              350, 400, 450,\n",
       "                                                              500],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800]},\n",
       "                   return_train_score=True, scoring=&#x27;average_precision&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
       "                   estimator=RandomForestClassifier(), n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60],\n",
       "                                        'min_samples_leaf': [200, 250, 300, 350,\n",
       "                                                             400, 450, 500, 550,\n",
       "                                                             600],\n",
       "                                        'min_samples_split': [200, 250, 300,\n",
       "                                                              350, 400, 450,\n",
       "                                                              500],\n",
       "                                        'n_estimators': [50, 100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800]},\n",
       "                   return_train_score=True, scoring='average_precision')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "\n",
    "SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "espaco_hiperp = {'n_estimators': [50, 100, 200, 300, 400, 500, 600, 700, 800],\n",
    "                 'max_depth': [10, 20, 30, 40, 50, 60],\n",
    "                 'min_samples_leaf': [200, 250, 300, 350, 400, 450, 500, 550, 600],\n",
    "                 'min_samples_split': [200, 250, 300, 350, 400, 450, 500]}\n",
    "\n",
    "RSCV = RandomizedSearchCV(estimator=RF,\n",
    "                          param_distributions=espaco_hiperp,\n",
    "                          cv=SKF,\n",
    "                          n_iter=100,\n",
    "                          #scoring='neg_log_loss',\n",
    "                          scoring='average_precision',\n",
    "                          return_train_score=True,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "RSCV.fit(X_treino_new, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 200,\n",
       " 'min_samples_leaf': 200,\n",
       " 'max_depth': 40}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6845150770758678)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSCV.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([4.86845617, 3.58653154, 1.46272874, 2.70147419, 4.75923405,\n",
       "        4.23301926, 8.12223926, 5.99446964, 6.97722163, 7.81923466,\n",
       "        2.77290573, 4.80812836, 5.15511975, 6.70228634, 8.76945825,\n",
       "        0.43328786, 0.47117105, 6.00725222, 5.21172857, 4.89290872,\n",
       "        8.79658041, 8.00307474, 0.89807844, 0.62710047, 0.44188461,\n",
       "        5.53268003, 8.75706701, 0.53832331, 6.39254422, 2.11789174,\n",
       "        0.54522724, 0.44471855, 4.54721613, 8.28712754, 0.5185123 ,\n",
       "        2.63024421, 5.26784425, 6.96839228, 4.3868794 , 3.5293417 ,\n",
       "        5.75598636, 0.48574781, 3.56553979, 3.58849993, 1.82425518,\n",
       "        0.55561538, 6.71463552, 1.70897508, 2.62502699, 3.33667932,\n",
       "        8.16294217, 3.42035189, 6.14710779, 0.48582764, 6.64102592,\n",
       "        2.25415335, 2.64876628, 3.50054007, 2.28762636, 1.09903078,\n",
       "        6.43593521, 4.81149731, 7.00919514, 5.55260425, 5.69952803,\n",
       "        7.4863946 , 2.74508457, 4.70637236, 3.45507221, 6.59783063,\n",
       "        1.06266031, 1.1560256 , 5.13391871, 5.61328197, 4.63810873,\n",
       "        1.0163588 , 4.83589306, 2.83003883, 0.58737679, 1.81744795,\n",
       "        8.70997462, 4.49547462, 9.35767694, 1.82662125, 8.13059878,\n",
       "        3.10206871, 1.10553908, 6.49454098, 0.47105665, 5.96211615,\n",
       "        8.59250712, 1.17548761, 4.34672904, 0.57720428, 6.52924514,\n",
       "        2.30042992, 0.92721386, 2.24911952, 6.51248884, 2.64634781]),\n",
       " 'std_fit_time': array([0.39808358, 0.30683367, 0.04450582, 0.18223997, 0.28770628,\n",
       "        0.29109912, 0.3380246 , 0.23553616, 0.18700805, 0.28052096,\n",
       "        0.17133709, 0.29181631, 0.61595845, 0.57796997, 0.67132608,\n",
       "        0.04322724, 0.02168926, 0.53185165, 0.54023076, 0.7743092 ,\n",
       "        0.74900817, 0.69502646, 0.07464836, 0.02230241, 0.05185272,\n",
       "        0.31875716, 0.40260169, 0.05745647, 0.37410473, 0.0852603 ,\n",
       "        0.04232477, 0.03292601, 0.47253123, 0.63730314, 0.05932807,\n",
       "        0.12080935, 0.42246876, 0.23649633, 0.08894418, 0.19436901,\n",
       "        0.33981997, 0.05004054, 0.1063754 , 0.14590045, 0.15036686,\n",
       "        0.03037941, 0.34775185, 0.12998138, 0.10731957, 0.20768318,\n",
       "        0.54031262, 0.18122009, 0.26589025, 0.01234078, 0.33005349,\n",
       "        0.0704723 , 0.12177172, 0.09880604, 0.08619092, 0.05799576,\n",
       "        0.38539645, 0.26730244, 0.44893664, 0.32800837, 0.29584653,\n",
       "        0.48295302, 0.21082862, 0.16285466, 0.12304842, 0.30269583,\n",
       "        0.05899698, 0.06378397, 0.36393508, 0.25806746, 0.28249469,\n",
       "        0.05009252, 0.18370803, 0.07467682, 0.06050906, 0.09867721,\n",
       "        0.50060196, 0.07699596, 0.56985605, 0.17382978, 0.2454171 ,\n",
       "        0.16087088, 0.02799384, 0.4426908 , 0.05265681, 0.32773869,\n",
       "        0.27665747, 0.06717142, 0.21814998, 0.05366029, 0.34177017,\n",
       "        0.18725605, 0.10195362, 0.17995582, 0.30893045, 0.13088497]),\n",
       " 'mean_score_time': array([0.1309361 , 0.07969675, 0.03564911, 0.07362232, 0.10708365,\n",
       "        0.09887509, 0.19581261, 0.13241892, 0.16485457, 0.17217703,\n",
       "        0.08184333, 0.09828153, 0.11666465, 0.13638287, 0.16974792,\n",
       "        0.01701698, 0.01740322, 0.16648774, 0.20705767, 0.10882888,\n",
       "        0.16087241, 0.17030807, 0.03273726, 0.02025151, 0.0185379 ,\n",
       "        0.13697481, 0.19577694, 0.02038326, 0.16213751, 0.05298362,\n",
       "        0.02166963, 0.01812024, 0.09812894, 0.19062119, 0.01991863,\n",
       "        0.0679615 , 0.13298697, 0.15949087, 0.10348063, 0.08034453,\n",
       "        0.12871957, 0.01666522, 0.08959794, 0.08978248, 0.04635501,\n",
       "        0.02149496, 0.14353838, 0.04724774, 0.07111697, 0.08054466,\n",
       "        0.19143281, 0.08453445, 0.14580879, 0.01936803, 0.14725595,\n",
       "        0.05843101, 0.06792169, 0.08253055, 0.05609517, 0.03112917,\n",
       "        0.15839458, 0.10760064, 0.16068621, 0.13026447, 0.13441157,\n",
       "        0.18242502, 0.07074814, 0.11128335, 0.08376575, 0.15032234,\n",
       "        0.03207378, 0.0317296 , 0.12523904, 0.13285432, 0.112922  ,\n",
       "        0.03429265, 0.12736101, 0.0732008 , 0.01932364, 0.0510314 ,\n",
       "        0.19642673, 0.14271841, 0.22141528, 0.05006208, 0.19978733,\n",
       "        0.07577786, 0.03258667, 0.17009559, 0.0170887 , 0.13560672,\n",
       "        0.17996778, 0.03182526, 0.11302724, 0.02060075, 0.15673079,\n",
       "        0.05965805, 0.03081584, 0.05320549, 0.16042128, 0.0634584 ]),\n",
       " 'std_score_time': array([0.04528619, 0.00796995, 0.00378407, 0.01981092, 0.00968567,\n",
       "        0.00523854, 0.04541177, 0.0129869 , 0.02088215, 0.0165329 ,\n",
       "        0.01282578, 0.0034075 , 0.01595373, 0.03199985, 0.01582289,\n",
       "        0.00164021, 0.00057492, 0.04521224, 0.04354933, 0.02169189,\n",
       "        0.01847154, 0.01628116, 0.0036462 , 0.00170366, 0.00346851,\n",
       "        0.01681534, 0.02744455, 0.00117357, 0.01979447, 0.00498861,\n",
       "        0.00308882, 0.0024568 , 0.01026267, 0.01659468, 0.00360387,\n",
       "        0.00726704, 0.01733247, 0.01632765, 0.01520737, 0.00665027,\n",
       "        0.01167545, 0.00041879, 0.0096744 , 0.0068156 , 0.00285379,\n",
       "        0.00308918, 0.01140113, 0.00643759, 0.00635021, 0.0069319 ,\n",
       "        0.0194875 , 0.00594577, 0.0144404 , 0.00165433, 0.01009503,\n",
       "        0.00606754, 0.00783393, 0.0064459 , 0.00589524, 0.00355519,\n",
       "        0.0117684 , 0.00690575, 0.01371632, 0.01338335, 0.0223436 ,\n",
       "        0.02284235, 0.00878774, 0.00850616, 0.00750461, 0.01562949,\n",
       "        0.00586356, 0.00271891, 0.01388301, 0.00973835, 0.00565223,\n",
       "        0.00446201, 0.01958563, 0.00772562, 0.00121653, 0.0046708 ,\n",
       "        0.01969986, 0.05533325, 0.0098897 , 0.00868095, 0.03160389,\n",
       "        0.00720329, 0.00289306, 0.01758781, 0.00086175, 0.0165896 ,\n",
       "        0.02102004, 0.00320945, 0.00877459, 0.00224944, 0.01638496,\n",
       "        0.00820804, 0.00467551, 0.00335634, 0.09848384, 0.0074965 ]),\n",
       " 'param_n_estimators': masked_array(data=[600, 400, 200, 300, 500, 600, 800, 700, 700, 700, 300,\n",
       "                    500, 500, 600, 700, 50, 50, 500, 500, 400, 700, 700,\n",
       "                    100, 50, 50, 500, 800, 50, 700, 200, 50, 50, 400, 700,\n",
       "                    50, 300, 500, 800, 400, 300, 500, 50, 400, 400, 200,\n",
       "                    50, 600, 200, 300, 300, 800, 400, 700, 50, 600, 200,\n",
       "                    300, 300, 200, 100, 700, 500, 800, 600, 500, 800, 300,\n",
       "                    500, 300, 600, 100, 100, 500, 600, 500, 100, 500, 300,\n",
       "                    50, 200, 800, 400, 800, 200, 800, 300, 100, 700, 50,\n",
       "                    500, 700, 100, 500, 50, 700, 200, 100, 200, 600, 300],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value=np.str_('?'),\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[400, 300, 500, 400, 450, 500, 200, 250, 500, 200, 350,\n",
       "                    200, 450, 200, 450, 500, 350, 450, 300, 350, 300, 400,\n",
       "                    350, 250, 450, 450, 250, 400, 200, 300, 400, 200, 300,\n",
       "                    300, 400, 250, 250, 400, 300, 400, 350, 250, 300, 350,\n",
       "                    400, 300, 200, 300, 250, 500, 200, 500, 350, 350, 350,\n",
       "                    400, 300, 500, 450, 200, 450, 400, 500, 200, 300, 200,\n",
       "                    450, 450, 200, 400, 350, 300, 400, 350, 250, 200, 450,\n",
       "                    500, 300, 200, 300, 200, 450, 300, 400, 300, 300, 350,\n",
       "                    250, 500, 450, 500, 350, 250, 400, 350, 400, 300, 250,\n",
       "                    450],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value=np.str_('?'),\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[300, 200, 500, 350, 250, 600, 250, 500, 400, 300, 500,\n",
       "                    600, 500, 550, 250, 500, 350, 200, 600, 550, 450, 300,\n",
       "                    600, 250, 600, 300, 300, 600, 550, 350, 350, 600, 300,\n",
       "                    200, 400, 600, 300, 550, 300, 200, 250, 350, 450, 500,\n",
       "                    500, 300, 250, 550, 550, 250, 350, 600, 550, 350, 250,\n",
       "                    250, 500, 200, 200, 250, 500, 450, 600, 500, 200, 450,\n",
       "                    550, 450, 200, 250, 250, 200, 350, 400, 450, 350, 400,\n",
       "                    400, 200, 450, 250, 300, 200, 600, 350, 350, 250, 500,\n",
       "                    450, 200, 200, 250, 550, 350, 500, 250, 600, 250, 250,\n",
       "                    500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value=np.str_('?'),\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[50, 60, 60, 20, 40, 10, 50, 50, 30, 20, 50, 60, 20, 50,\n",
       "                    10, 10, 10, 50, 60, 20, 20, 20, 10, 20, 30, 40, 30, 30,\n",
       "                    10, 30, 30, 40, 40, 10, 40, 50, 50, 10, 30, 20, 10, 40,\n",
       "                    20, 40, 10, 20, 20, 30, 30, 40, 40, 50, 50, 30, 10, 40,\n",
       "                    30, 20, 10, 60, 60, 40, 10, 50, 60, 40, 40, 10, 40, 10,\n",
       "                    10, 10, 40, 20, 50, 50, 50, 30, 20, 40, 30, 20, 20, 30,\n",
       "                    10, 40, 60, 40, 10, 10, 60, 30, 30, 20, 20, 50, 30, 60,\n",
       "                    60, 30],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value=np.str_('?'),\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 600,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 300,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 200,\n",
       "   'max_depth': 60},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 500,\n",
       "   'min_samples_leaf': 500,\n",
       "   'max_depth': 60},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 350,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 600,\n",
       "   'min_samples_split': 500,\n",
       "   'min_samples_leaf': 600,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 800,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 700,\n",
       "   'min_samples_split': 250,\n",
       "   'min_samples_leaf': 500,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 700,\n",
       "   'min_samples_split': 500,\n",
       "   'min_samples_leaf': 400,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 700,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 300,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 500,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 600,\n",
       "   'max_depth': 60},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 500,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 600,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 550,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 700,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 500,\n",
       "   'min_samples_leaf': 500,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 350,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 200,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 600,\n",
       "   'max_depth': 60},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 550,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 700,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 450,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 700,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 300,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 600,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 250,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 600,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 300,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 800,\n",
       "   'min_samples_split': 250,\n",
       "   'min_samples_leaf': 300,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 600,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 700,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 550,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 350,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 350,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 600,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 300,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 700,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 200,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 400,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 250,\n",
       "   'min_samples_leaf': 600,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 250,\n",
       "   'min_samples_leaf': 300,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 800,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 550,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 300,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 200,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 250,\n",
       "   'min_samples_leaf': 350,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 450,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 500,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 500,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 300,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 600,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 550,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 250,\n",
       "   'min_samples_leaf': 550,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 500,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 800,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 350,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 500,\n",
       "   'min_samples_leaf': 600,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 700,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 550,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 350,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 600,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 500,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 500,\n",
       "   'min_samples_leaf': 200,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 200,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 60},\n",
       "  {'n_estimators': 700,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 500,\n",
       "   'max_depth': 60},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 450,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 800,\n",
       "   'min_samples_split': 500,\n",
       "   'min_samples_leaf': 600,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 600,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 500,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 200,\n",
       "   'max_depth': 60},\n",
       "  {'n_estimators': 800,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 450,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 550,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 450,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 200,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 600,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 200,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 350,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 600,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 400,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 250,\n",
       "   'min_samples_leaf': 450,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 350,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 400,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 500,\n",
       "   'min_samples_leaf': 400,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 200,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 450,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 800,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 400,\n",
       "   'min_samples_split': 200,\n",
       "   'min_samples_leaf': 300,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 800,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 200,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 600,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 800,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 350,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 350,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 60},\n",
       "  {'n_estimators': 700,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 500,\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 250,\n",
       "   'min_samples_leaf': 450,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 500,\n",
       "   'min_samples_leaf': 200,\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 700,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 200,\n",
       "   'max_depth': 60},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 500,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 500,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 550,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 250,\n",
       "   'min_samples_leaf': 350,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 700,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 500,\n",
       "   'max_depth': 20},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 350,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 400,\n",
       "   'min_samples_leaf': 600,\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 200,\n",
       "   'min_samples_split': 300,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 60},\n",
       "  {'n_estimators': 600,\n",
       "   'min_samples_split': 250,\n",
       "   'min_samples_leaf': 250,\n",
       "   'max_depth': 60},\n",
       "  {'n_estimators': 300,\n",
       "   'min_samples_split': 450,\n",
       "   'min_samples_leaf': 500,\n",
       "   'max_depth': 30}],\n",
       " 'split0_test_score': array([0.65933891, 0.67657734, 0.62324622, 0.6528745 , 0.65900668,\n",
       "        0.62309886, 0.66662783, 0.62906825, 0.64401117, 0.64607996,\n",
       "        0.63876864, 0.6280172 , 0.63034399, 0.63295512, 0.66303496,\n",
       "        0.61384562, 0.64864198, 0.67559574, 0.62058615, 0.62755395,\n",
       "        0.63414804, 0.64318827, 0.62099127, 0.66057408, 0.62151697,\n",
       "        0.65392789, 0.65253607, 0.60729661, 0.63606428, 0.64819426,\n",
       "        0.61839011, 0.62565164, 0.64322574, 0.67247185, 0.60692658,\n",
       "        0.62399128, 0.64278649, 0.62854447, 0.63724795, 0.66923994,\n",
       "        0.66052351, 0.61019687, 0.6421992 , 0.62859692, 0.62458408,\n",
       "        0.6467769 , 0.6625322 , 0.64655361, 0.63454374, 0.65513286,\n",
       "        0.64035409, 0.62709648, 0.63607892, 0.63051094, 0.66748558,\n",
       "        0.65937499, 0.62789109, 0.66294585, 0.67259006, 0.67544804,\n",
       "        0.64256832, 0.63165549, 0.62695004, 0.62314186, 0.67620571,\n",
       "        0.64183458, 0.62292353, 0.62919664, 0.67657247, 0.66863665,\n",
       "        0.65987041, 0.67186988, 0.64337122, 0.64042465, 0.63502342,\n",
       "        0.62696394, 0.62581079, 0.63083108, 0.65331934, 0.62051302,\n",
       "        0.66173758, 0.64719566, 0.67247722, 0.61689519, 0.64799967,\n",
       "        0.64288306, 0.65551425, 0.61885484, 0.63139506, 0.66998491,\n",
       "        0.6777619 , 0.66465224, 0.62981589, 0.63637411, 0.62753271,\n",
       "        0.66366079, 0.62523641, 0.65214888, 0.65911271, 0.62320761]),\n",
       " 'split1_test_score': array([0.65364701, 0.67887105, 0.63472806, 0.64278197, 0.66975648,\n",
       "        0.64475481, 0.66185566, 0.64614021, 0.64191136, 0.64770141,\n",
       "        0.64622323, 0.63951255, 0.63921348, 0.64190202, 0.67075939,\n",
       "        0.59924681, 0.61449727, 0.67612909, 0.64584885, 0.64487771,\n",
       "        0.64780485, 0.64895529, 0.63166185, 0.65934594, 0.62898445,\n",
       "        0.65613995, 0.64202566, 0.6232226 , 0.64297748, 0.62510619,\n",
       "        0.6188242 , 0.61806255, 0.65322077, 0.67848756, 0.61360069,\n",
       "        0.62704799, 0.65119432, 0.63673629, 0.65035169, 0.68231849,\n",
       "        0.66208091, 0.62123979, 0.6482725 , 0.63186003, 0.64812337,\n",
       "        0.63136869, 0.65633851, 0.64102713, 0.6479332 , 0.65726093,\n",
       "        0.648663  , 0.65079708, 0.64044999, 0.64048457, 0.66553467,\n",
       "        0.64559468, 0.6435485 , 0.67436342, 0.67920814, 0.66117645,\n",
       "        0.6462012 , 0.64289725, 0.64545625, 0.64312868, 0.67583502,\n",
       "        0.64147099, 0.63497788, 0.64208901, 0.67735346, 0.66017808,\n",
       "        0.66549066, 0.67864026, 0.64879309, 0.63952268, 0.64855504,\n",
       "        0.6400838 , 0.63296701, 0.62786384, 0.66931328, 0.64457745,\n",
       "        0.66388183, 0.64730819, 0.67873242, 0.64195069, 0.65524647,\n",
       "        0.63791191, 0.6683415 , 0.61961403, 0.62384891, 0.67244191,\n",
       "        0.67685322, 0.66166646, 0.63167666, 0.63775757, 0.63749125,\n",
       "        0.65745292, 0.64373994, 0.65888399, 0.66481215, 0.62228232]),\n",
       " 'split2_test_score': array([0.66811502, 0.68419188, 0.66058482, 0.6557257 , 0.67923023,\n",
       "        0.63669854, 0.68043304, 0.65193586, 0.65874735, 0.67150121,\n",
       "        0.66532206, 0.66002744, 0.66726165, 0.6503309 , 0.67924372,\n",
       "        0.64307416, 0.66889012, 0.68777491, 0.651544  , 0.64015721,\n",
       "        0.66982808, 0.66433585, 0.65468003, 0.65788041, 0.64814598,\n",
       "        0.67180688, 0.67317894, 0.6321867 , 0.65886289, 0.67189238,\n",
       "        0.65247815, 0.62732869, 0.66362704, 0.69141207, 0.6751259 ,\n",
       "        0.6537706 , 0.67563904, 0.65335336, 0.6745294 , 0.69543221,\n",
       "        0.68701263, 0.68086947, 0.66211196, 0.64190243, 0.65364684,\n",
       "        0.68195257, 0.68115613, 0.61194144, 0.65088094, 0.68284966,\n",
       "        0.67072976, 0.64897056, 0.65160665, 0.65847401, 0.6748886 ,\n",
       "        0.66687633, 0.65166242, 0.68783022, 0.6921569 , 0.69081003,\n",
       "        0.65746659, 0.66720443, 0.65665593, 0.65072907, 0.69531872,\n",
       "        0.66890466, 0.64351694, 0.67442955, 0.69541169, 0.68554503,\n",
       "        0.66073779, 0.68762704, 0.66480192, 0.65779562, 0.64610033,\n",
       "        0.64392661, 0.66704215, 0.66474658, 0.68395967, 0.66414066,\n",
       "        0.68049844, 0.66291389, 0.68996322, 0.63859186, 0.66627395,\n",
       "        0.67245074, 0.66545917, 0.65496718, 0.65425858, 0.68815677,\n",
       "        0.68737285, 0.6669874 , 0.65965045, 0.66356332, 0.66347823,\n",
       "        0.67465949, 0.64584284, 0.67329457, 0.6810275 , 0.66083828]),\n",
       " 'split3_test_score': array([0.66862516, 0.68748352, 0.66288696, 0.6586282 , 0.67363757,\n",
       "        0.65759138, 0.67062539, 0.65301744, 0.64710451, 0.6711191 ,\n",
       "        0.65642907, 0.65592389, 0.65328032, 0.65096039, 0.66773323,\n",
       "        0.62782143, 0.65550953, 0.68399246, 0.65578063, 0.66225622,\n",
       "        0.65305819, 0.66644292, 0.6402    , 0.68677116, 0.65498861,\n",
       "        0.65886464, 0.66515361, 0.65696666, 0.65990395, 0.65342353,\n",
       "        0.66789542, 0.63652003, 0.65984614, 0.688859  , 0.64277057,\n",
       "        0.65071797, 0.6626567 , 0.66129804, 0.66714276, 0.68778062,\n",
       "        0.67790407, 0.62940059, 0.66374843, 0.65673092, 0.65673145,\n",
       "        0.6619085 , 0.67382256, 0.6528924 , 0.64921885, 0.6732271 ,\n",
       "        0.66420992, 0.64390618, 0.66281165, 0.63468093, 0.67487143,\n",
       "        0.66287617, 0.66173942, 0.6774495 , 0.6799639 , 0.65827014,\n",
       "        0.64827682, 0.65509562, 0.65197576, 0.65517754, 0.68523741,\n",
       "        0.6528973 , 0.66033256, 0.66297789, 0.69075688, 0.66993833,\n",
       "        0.67623647, 0.6958345 , 0.66657222, 0.65218016, 0.65052512,\n",
       "        0.66861224, 0.65323864, 0.63672553, 0.67303081, 0.65191562,\n",
       "        0.670208  , 0.66281455, 0.68368387, 0.64630786, 0.66083601,\n",
       "        0.66846193, 0.67514418, 0.65387182, 0.62886464, 0.68226674,\n",
       "        0.68175278, 0.67730246, 0.65933116, 0.66665042, 0.65674021,\n",
       "        0.67078399, 0.65641534, 0.66866489, 0.66444684, 0.64616785]),\n",
       " 'split4_test_score': array([0.66322938, 0.67749651, 0.66680718, 0.66650668, 0.6697984 ,\n",
       "        0.64822869, 0.67309765, 0.64664856, 0.6578958 , 0.66812825,\n",
       "        0.65332287, 0.65655467, 0.6480461 , 0.65659516, 0.67059583,\n",
       "        0.62243877, 0.67280921, 0.67964023, 0.65037643, 0.64125035,\n",
       "        0.66021084, 0.66383313, 0.6384489 , 0.65329888, 0.64982621,\n",
       "        0.6660112 , 0.66046083, 0.64860844, 0.65753874, 0.66258421,\n",
       "        0.66381067, 0.64908279, 0.67006134, 0.68275556, 0.65829695,\n",
       "        0.65247159, 0.6676071 , 0.65385666, 0.65842623, 0.68080981,\n",
       "        0.6703411 , 0.66552411, 0.65187799, 0.65435466, 0.64503897,\n",
       "        0.66816238, 0.6700447 , 0.62531249, 0.65837458, 0.6730557 ,\n",
       "        0.65918862, 0.65029262, 0.65709978, 0.67050836, 0.6733058 ,\n",
       "        0.66520023, 0.65103864, 0.68127315, 0.68299525, 0.67120882,\n",
       "        0.64751241, 0.66050661, 0.65107834, 0.64410819, 0.6826365 ,\n",
       "        0.66621208, 0.64884525, 0.65883824, 0.68248089, 0.67264547,\n",
       "        0.6685565 , 0.67485038, 0.66566041, 0.66338631, 0.65256218,\n",
       "        0.6677308 , 0.65649409, 0.6581933 , 0.68382267, 0.66132389,\n",
       "        0.667623  , 0.67207993, 0.68039679, 0.64619526, 0.6584744 ,\n",
       "        0.6618534 , 0.67156814, 0.65509883, 0.64019927, 0.68287625,\n",
       "        0.68268338, 0.67181047, 0.65158664, 0.65956073, 0.65244199,\n",
       "        0.66604477, 0.65681915, 0.66710183, 0.67109342, 0.65997224]),\n",
       " 'mean_test_score': array([0.66259109, 0.68092406, 0.64965065, 0.65530341, 0.67028587,\n",
       "        0.64207445, 0.67052792, 0.64536206, 0.64993404, 0.66090599,\n",
       "        0.65201317, 0.64800715, 0.64762911, 0.64654872, 0.67027343,\n",
       "        0.62128536, 0.65206962, 0.68062648, 0.64482721, 0.64321909,\n",
       "        0.65301   , 0.65735109, 0.63719641, 0.66357409, 0.64069244,\n",
       "        0.66135011, 0.65867102, 0.6336562 , 0.65106947, 0.65224012,\n",
       "        0.64427971, 0.63132914, 0.6579962 , 0.68279721, 0.63934414,\n",
       "        0.64159988, 0.65997673, 0.64675776, 0.6575396 , 0.68311621,\n",
       "        0.67157244, 0.64144616, 0.65364202, 0.64268899, 0.64562494,\n",
       "        0.65803381, 0.66877882, 0.63554541, 0.64819026, 0.66830525,\n",
       "        0.65662908, 0.64421258, 0.6496094 , 0.64693176, 0.67121722,\n",
       "        0.65998448, 0.64717601, 0.67677243, 0.68138285, 0.6713827 ,\n",
       "        0.64840507, 0.65147188, 0.64642326, 0.64325707, 0.68304667,\n",
       "        0.65426392, 0.64211923, 0.65350627, 0.68451508, 0.67138871,\n",
       "        0.66617837, 0.68176441, 0.65783977, 0.65066189, 0.64655322,\n",
       "        0.64946348, 0.64711054, 0.64367207, 0.67268915, 0.64849413,\n",
       "        0.66878977, 0.65846244, 0.68105071, 0.63798817, 0.6577661 ,\n",
       "        0.65671221, 0.66720545, 0.64048134, 0.63571329, 0.67914531,\n",
       "        0.68128483, 0.66848381, 0.64641216, 0.65278123, 0.64753688,\n",
       "        0.66652039, 0.64561074, 0.66401883, 0.66809852, 0.64249366]),\n",
       " 'std_test_score': array([0.00561969, 0.00420861, 0.01737228, 0.00773863, 0.00661776,\n",
       "        0.01161729, 0.00624729, 0.00859731, 0.00705002, 0.01151434,\n",
       "        0.00902533, 0.01226359, 0.01254707, 0.00825926, 0.00528497,\n",
       "        0.01455919, 0.02072835, 0.0046677 , 0.01252645, 0.0111697 ,\n",
       "        0.01197973, 0.0094291 , 0.01104088, 0.01185731, 0.01302411,\n",
       "        0.00662544, 0.01068094, 0.01773581, 0.00970848, 0.01579387,\n",
       "        0.02156214, 0.0106431 , 0.00918333, 0.00687239, 0.02594189,\n",
       "        0.01320061, 0.01169058, 0.01214471, 0.01300059, 0.00862493,\n",
       "        0.00992142, 0.02706975, 0.00820684, 0.01139943, 0.01128724,\n",
       "        0.0174783 , 0.00864894, 0.01492654, 0.00772414, 0.01052445,\n",
       "        0.01087367, 0.00889961, 0.01001362, 0.01516821, 0.00393474,\n",
       "        0.00762235, 0.01124462, 0.00824582, 0.00636767, 0.01157657,\n",
       "        0.00493658, 0.01271601, 0.01036676, 0.01098445, 0.0071327 ,\n",
       "        0.01163722, 0.01263639, 0.01598272, 0.00743247, 0.00821385,\n",
       "        0.00594448, 0.00880685, 0.00976802, 0.00942326, 0.0061487 ,\n",
       "        0.01628026, 0.01534009, 0.01495357, 0.01129321, 0.0156167 ,\n",
       "        0.00654655, 0.00975243, 0.00575627, 0.01093209, 0.00606698,\n",
       "        0.01383391, 0.00667953, 0.01735491, 0.01068051, 0.00683693,\n",
       "        0.00377595, 0.00551782, 0.0131263 , 0.01303437, 0.01314511,\n",
       "        0.00591686, 0.01149813, 0.00754178, 0.00749677, 0.01694683]),\n",
       " 'rank_test_score': array([ 31,   9,  59,  46,  19,  88,  18,  78,  58,  33,  54,  65,  66,\n",
       "         73,  20, 100,  53,  10,  79,  84,  50,  43,  95,  30,  91,  32,\n",
       "         36,  98,  56,  52,  80,  99,  39,   4,  93,  89,  35,  71,  42,\n",
       "          2,  14,  90,  48,  85,  76,  38,  22,  97,  64,  24,  45,  81,\n",
       "         60,  70,  17,  34,  68,  12,   6,  16,  63,  55,  74,  83,   3,\n",
       "         47,  87,  49,   1,  15,  28,   5,  40,  57,  72,  61,  69,  82,\n",
       "         13,  62,  21,  37,   8,  94,  41,  44,  26,  92,  96,  11,   7,\n",
       "         23,  75,  51,  67,  27,  77,  29,  25,  86], dtype=int32),\n",
       " 'split0_train_score': array([0.68715487, 0.69968206, 0.65259752, 0.68231064, 0.68475009,\n",
       "        0.65962077, 0.6921492 , 0.66202955, 0.67271556, 0.67521992,\n",
       "        0.67490819, 0.66127756, 0.66305669, 0.66755356, 0.69037477,\n",
       "        0.6522794 , 0.69071636, 0.69965593, 0.65682266, 0.66147729,\n",
       "        0.66483888, 0.67305642, 0.65435887, 0.69602843, 0.66034735,\n",
       "        0.68342662, 0.68165621, 0.65098948, 0.66330532, 0.67649879,\n",
       "        0.67807996, 0.6536497 , 0.67265872, 0.69706304, 0.64505415,\n",
       "        0.66474482, 0.67132362, 0.66553031, 0.67116483, 0.69864708,\n",
       "        0.68787495, 0.65073974, 0.67530126, 0.66600257, 0.6542409 ,\n",
       "        0.66765174, 0.68542542, 0.67444777, 0.6669774 , 0.68233579,\n",
       "        0.67047563, 0.66334808, 0.66779913, 0.66123094, 0.69274745,\n",
       "        0.68951481, 0.66069602, 0.69173617, 0.69624529, 0.69515814,\n",
       "        0.67137869, 0.66195645, 0.66289933, 0.65414682, 0.70159688,\n",
       "        0.67270024, 0.64708712, 0.66212199, 0.70003799, 0.69356341,\n",
       "        0.68854775, 0.69950059, 0.67150665, 0.66493868, 0.66533015,\n",
       "        0.66551643, 0.65934074, 0.66518154, 0.67800262, 0.6568221 ,\n",
       "        0.68590762, 0.68251424, 0.69622341, 0.64811218, 0.68039141,\n",
       "        0.67558185, 0.68836122, 0.65316224, 0.66441889, 0.69343042,\n",
       "        0.69984022, 0.69003826, 0.66336895, 0.67386051, 0.65818756,\n",
       "        0.69602777, 0.65888969, 0.67873445, 0.68607631, 0.65165614]),\n",
       " 'split1_train_score': array([0.67176522, 0.69794487, 0.64755694, 0.65700921, 0.69010653,\n",
       "        0.64986949, 0.68231861, 0.65534826, 0.66225526, 0.66423611,\n",
       "        0.65373796, 0.64734831, 0.65245944, 0.65723143, 0.68683405,\n",
       "        0.62686476, 0.64472557, 0.69480529, 0.65234792, 0.65772061,\n",
       "        0.6611413 , 0.66608879, 0.639787  , 0.68769635, 0.63779553,\n",
       "        0.67481025, 0.66184139, 0.63225972, 0.65586431, 0.64635055,\n",
       "        0.6409777 , 0.61915463, 0.66966016, 0.69997035, 0.64887368,\n",
       "        0.63576734, 0.66691447, 0.65058729, 0.66548375, 0.70158634,\n",
       "        0.67926994, 0.64292417, 0.66549311, 0.64647405, 0.66310863,\n",
       "        0.64928031, 0.67909868, 0.65924412, 0.6592466 , 0.67416446,\n",
       "        0.66288025, 0.65699236, 0.64869829, 0.66041604, 0.68598755,\n",
       "        0.6658007 , 0.65927958, 0.69384554, 0.69778294, 0.68112534,\n",
       "        0.66146547, 0.65903222, 0.6556941 , 0.65701588, 0.69668631,\n",
       "        0.65963461, 0.64964879, 0.6586841 , 0.69994735, 0.68325235,\n",
       "        0.68678252, 0.70007792, 0.6670417 , 0.65787859, 0.66338   ,\n",
       "        0.66127212, 0.65400345, 0.6481414 , 0.69000756, 0.66416279,\n",
       "        0.68216309, 0.66327523, 0.69730601, 0.64997008, 0.67240291,\n",
       "        0.65791683, 0.68556016, 0.63771291, 0.64234619, 0.69503364,\n",
       "        0.69735477, 0.68845372, 0.6466306 , 0.66033255, 0.65748468,\n",
       "        0.67517279, 0.64877413, 0.67905964, 0.68332361, 0.63610831]),\n",
       " 'split2_train_score': array([0.66620465, 0.68824874, 0.65088279, 0.65310531, 0.67725403,\n",
       "        0.64237834, 0.67773899, 0.64297729, 0.64951375, 0.66635719,\n",
       "        0.65348989, 0.6527124 , 0.65992914, 0.65143385, 0.67704636,\n",
       "        0.63797528, 0.66028183, 0.68589235, 0.65260447, 0.6432934 ,\n",
       "        0.65651224, 0.6626481 , 0.6522634 , 0.66328363, 0.65402501,\n",
       "        0.6683455 , 0.67006902, 0.62795451, 0.65723786, 0.66640131,\n",
       "        0.65592521, 0.63590336, 0.66312063, 0.6935271 , 0.6733201 ,\n",
       "        0.65169427, 0.67090515, 0.65414166, 0.66809022, 0.69262565,\n",
       "        0.68654246, 0.66021657, 0.6520718 , 0.64304595, 0.64837296,\n",
       "        0.67084384, 0.67710215, 0.62083657, 0.65425535, 0.67806536,\n",
       "        0.66368753, 0.64628684, 0.64684495, 0.64775408, 0.67509874,\n",
       "        0.66453606, 0.6450101 , 0.68603749, 0.69186776, 0.68302271,\n",
       "        0.65188716, 0.65733416, 0.65726591, 0.64297332, 0.69284058,\n",
       "        0.65851736, 0.64765298, 0.66228758, 0.69285404, 0.68743338,\n",
       "        0.65631295, 0.6910069 , 0.65795371, 0.65273881, 0.6451241 ,\n",
       "        0.63834477, 0.65810844, 0.65573619, 0.6882568 , 0.65900947,\n",
       "        0.6791332 , 0.65715331, 0.68852609, 0.65037874, 0.66208211,\n",
       "        0.67008771, 0.6675176 , 0.65102095, 0.64354179, 0.68876694,\n",
       "        0.69028541, 0.67399296, 0.65438688, 0.66109834, 0.65658201,\n",
       "        0.68004194, 0.65344698, 0.67419335, 0.67764051, 0.65580802]),\n",
       " 'split3_train_score': array([0.66459203, 0.68874433, 0.65501241, 0.65566124, 0.67336659,\n",
       "        0.64594139, 0.67438949, 0.64406407, 0.64801168, 0.6691069 ,\n",
       "        0.64553419, 0.64599093, 0.64589145, 0.63988896, 0.67198415,\n",
       "        0.62058873, 0.6500426 , 0.6885361 , 0.64714253, 0.65128597,\n",
       "        0.6482462 , 0.66456773, 0.63474352, 0.67993139, 0.6506235 ,\n",
       "        0.65717305, 0.66345281, 0.64556362, 0.64448814, 0.64828344,\n",
       "        0.65642754, 0.62508531, 0.66032727, 0.69239591, 0.6308387 ,\n",
       "        0.64207064, 0.66508904, 0.64972782, 0.66607015, 0.69323667,\n",
       "        0.67628692, 0.6227934 , 0.65812706, 0.64987276, 0.64817338,\n",
       "        0.66439678, 0.67626643, 0.64258234, 0.63639343, 0.67462952,\n",
       "        0.66275405, 0.63420546, 0.65162766, 0.6262669 , 0.67996492,\n",
       "        0.66335457, 0.65211898, 0.67930891, 0.68959194, 0.67039289,\n",
       "        0.6392704 , 0.65570587, 0.64302961, 0.64842053, 0.69126137,\n",
       "        0.6482409 , 0.64828888, 0.65958672, 0.69320565, 0.67607335,\n",
       "        0.67275856, 0.69313188, 0.66563615, 0.65058545, 0.64532683,\n",
       "        0.66659499, 0.65024888, 0.63931323, 0.68080745, 0.64682272,\n",
       "        0.67566978, 0.66330178, 0.68581326, 0.63168742, 0.65722923,\n",
       "        0.66480844, 0.67706274, 0.65113049, 0.61757977, 0.68569774,\n",
       "        0.6897527 , 0.67410228, 0.65060609, 0.65986428, 0.64909664,\n",
       "        0.67228363, 0.65004766, 0.67004483, 0.6711176 , 0.63364969]),\n",
       " 'split4_train_score': array([0.66390332, 0.69387691, 0.66608346, 0.66716081, 0.68050088,\n",
       "        0.64480625, 0.68655217, 0.64117358, 0.65771086, 0.67318697,\n",
       "        0.65177739, 0.65148585, 0.64391357, 0.65951183, 0.68183054,\n",
       "        0.61893279, 0.67622728, 0.69804685, 0.64900646, 0.63551619,\n",
       "        0.65722269, 0.66895361, 0.62815711, 0.67639195, 0.65599509,\n",
       "        0.67221866, 0.66376593, 0.65007384, 0.65377655, 0.66092035,\n",
       "        0.6743752 , 0.63854287, 0.67333203, 0.70176684, 0.66031678,\n",
       "        0.65201374, 0.67312864, 0.65341843, 0.66433622, 0.69538776,\n",
       "        0.68272375, 0.66411651, 0.65202211, 0.65451655, 0.64077756,\n",
       "        0.67038871, 0.68054375, 0.61886404, 0.66243219, 0.68912772,\n",
       "        0.65973038, 0.64386727, 0.65559624, 0.6680392 , 0.68608465,\n",
       "        0.67477522, 0.64209362, 0.69652707, 0.70142223, 0.69111522,\n",
       "        0.64270349, 0.66089216, 0.64957747, 0.64205554, 0.69981447,\n",
       "        0.66426384, 0.64992202, 0.65635834, 0.69678539, 0.68565798,\n",
       "        0.68090189, 0.68796013, 0.6629653 , 0.66237337, 0.64824902,\n",
       "        0.66586254, 0.65263385, 0.65311019, 0.69227956, 0.65949995,\n",
       "        0.67883843, 0.67380531, 0.69675238, 0.65262855, 0.65287161,\n",
       "        0.66958042, 0.68902859, 0.65491893, 0.62503601, 0.69889059,\n",
       "        0.69924626, 0.68655136, 0.6476834 , 0.65021747, 0.65272042,\n",
       "        0.67643501, 0.65599853, 0.68284542, 0.6847903 , 0.66374627]),\n",
       " 'mean_train_score': array([0.67072402, 0.69369938, 0.65442662, 0.66304944, 0.68119562,\n",
       "        0.64852325, 0.68262969, 0.64911855, 0.65804142, 0.66962142,\n",
       "        0.65588952, 0.65176301, 0.65305006, 0.65512393, 0.68161397,\n",
       "        0.63132819, 0.66439873, 0.6933873 , 0.65158481, 0.64985869,\n",
       "        0.65759226, 0.66706293, 0.64186198, 0.68066635, 0.65175729,\n",
       "        0.67119482, 0.66815707, 0.64136824, 0.65493444, 0.65969089,\n",
       "        0.66115712, 0.63446717, 0.66781976, 0.69694465, 0.65168068,\n",
       "        0.64925816, 0.66947218, 0.6546811 , 0.66702903, 0.6962967 ,\n",
       "        0.6825396 , 0.64815808, 0.66060307, 0.65198238, 0.65093469,\n",
       "        0.66451228, 0.67968729, 0.64319497, 0.65586099, 0.67966457,\n",
       "        0.66390557, 0.64894   , 0.65411326, 0.65274143, 0.68397666,\n",
       "        0.67159627, 0.65183966, 0.68949104, 0.69538203, 0.68416286,\n",
       "        0.65334104, 0.65898417, 0.65369328, 0.64892242, 0.69643992,\n",
       "        0.66067139, 0.64851996, 0.65980775, 0.69656608, 0.68519609,\n",
       "        0.67706073, 0.69433548, 0.6650207 , 0.65770298, 0.65348202,\n",
       "        0.65951817, 0.65486707, 0.65229651, 0.6858708 , 0.65726341,\n",
       "        0.68034243, 0.66800997, 0.69292423, 0.64655539, 0.66499545,\n",
       "        0.66759505, 0.68150606, 0.6495891 , 0.63858453, 0.69236387,\n",
       "        0.69529587, 0.68262772, 0.65253519, 0.66107463, 0.65481426,\n",
       "        0.67999223, 0.6534314 , 0.67697554, 0.68058966, 0.64819368]),\n",
       " 'std_train_score': array([0.00866724, 0.00464995, 0.00631383, 0.01075037, 0.00581981,\n",
       "        0.00605325, 0.00629164, 0.00814725, 0.00901679, 0.00409824,\n",
       "        0.00996233, 0.00537236, 0.00751697, 0.00920773, 0.00659764,\n",
       "        0.01242611, 0.01698595, 0.00534278, 0.00332983, 0.00946202,\n",
       "        0.00554547, 0.00363765, 0.01007138, 0.01101258, 0.00765646,\n",
       "        0.00858446, 0.00731002, 0.00947471, 0.00611077, 0.01128841,\n",
       "        0.01355028, 0.01190913, 0.00520398, 0.00359981, 0.0143459 ,\n",
       "        0.00986942, 0.00298679, 0.00567248, 0.00239957, 0.00338145,\n",
       "        0.00434303, 0.01467995, 0.00885997, 0.00797044, 0.00743627,\n",
       "        0.00795618, 0.00323701, 0.02157119, 0.01058094, 0.00556502,\n",
       "        0.00355029, 0.01022068, 0.00745427, 0.01477002, 0.00600543,\n",
       "        0.00982385, 0.00742285, 0.00614997, 0.00421589, 0.008595  ,\n",
       "        0.01187112, 0.00227802, 0.00681428, 0.00592615, 0.003945  ,\n",
       "        0.00797284, 0.00110437, 0.00222329, 0.00311791, 0.0056962 ,\n",
       "        0.01174903, 0.00475031, 0.00448771, 0.00546811, 0.00896766,\n",
       "        0.01074896, 0.00339355, 0.00853637, 0.00550316, 0.00574204,\n",
       "        0.0034596 , 0.00901567, 0.0047885 , 0.00757154, 0.01007666,\n",
       "        0.00592245, 0.0081907 , 0.00610974, 0.01631503, 0.00465271,\n",
       "        0.00438924, 0.00709219, 0.00604855, 0.00752825, 0.00342668,\n",
       "        0.00839577, 0.00372889, 0.00441968, 0.0055433 , 0.01157094])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSCV.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(RSCV.cv_results_['mean_train_score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(RSCV.cv_results_['mean_test_score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste do XGBoost considerando os parâmetros: quantidade de árvores (n_estimators), profundidade da árvore (max_depth), número mínimo de instância em um nó filho (min_child_weight), amostra (proporção de variáveis) de colunas para a construção de uma árvore (colsample_bytree), amostra da base de treino para a construção da árvore (subsample), amostra de colunas para a cada split/divisão de um nó pai (colsample_bynode), valor base (bias) para a predição ou predição inicial para todas as instância (base_value) e a taxa de aprendizado que é o ponderador das árvores sequenciais construídas na minimização do erro (learning_rate). A documentação para o XGBoost é: https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:03<01:20,  3.33s/trial, best loss: 0.4408149619865551]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:06<01:16,  3.33s/trial, best loss: 0.4186012263101865]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:09<01:12,  3.31s/trial, best loss: 0.4186012263101865]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [00:13<01:10,  3.38s/trial, best loss: 0.4186012263101865]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    #test_imbalanced = [{0: len(y_treino2)/(2*np.bincount(y_treino2))[0], 1:len(y_teste2)/(2*np.bincount(y_teste2))[1]}, {0: 1, 1:1}]\n",
    "    \n",
    "    space = {\n",
    "        \"n_estimators\": hp.choice('n_estimators', np.arange(10, 500, dtype=int)),\n",
    "        \"max_depth\": hp.choice('max_depth', np.arange(10, 300, dtype=int)),\n",
    "        \"min_child_weight\": hp.choice('min_child_weight', np.arange(100, 500, dtype=int)),\n",
    "        \"colsample_bytree\": hp.quniform('colsample_bytree', 0.2, 1, 0.05),\n",
    "        \"subsample\": hp.quniform('subsample', 0.2, 1, 0.05),\n",
    "        \"colsample_bynode\": hp.quniform('colsample_bynode', 0.2, 1, 0.05),\n",
    "        \"base_score\": hp.quniform('base_score', 0.1, 1, 0.05),\n",
    "        \"learning_rate\": hp.quniform('learning_rate', 0.0025, 0.5, 0.025)\n",
    "\n",
    "    }\n",
    "    \n",
    "    with mlflow.start_run(run_name = 'XGBoost1', experiment_id=experiment.experiment_id) as run:\n",
    "        best_params = fmin(\n",
    "            fn = partial(\n",
    "                func_objetivo,\n",
    "                expr = experiment.experiment_id,\n",
    "                modelo = 'XGB',\n",
    "                X_treino = X_treino2,\n",
    "                X_teste = X_teste2,\n",
    "                y_treino = y_treino2,\n",
    "                y_teste = y_teste2\n",
    "            ),\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 25,\n",
    "            trials = Trials(),\n",
    "            timeout = 10\n",
    "        )\n",
    "        \n",
    "        # Identificado o melhor conjunto de hiperparâmetros, treina o modelo com toda a base de treino e metrifica os escores na base de validação\n",
    "\n",
    "        clf = xgb.XGBClassifier(**best_params)\n",
    "        clf.fit(X_treino_new, y_treino)\n",
    "                   \n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('aucpr_val', average_precision_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('log_loss_val', log_loss(y_val, clf.predict_proba(X_val_new)[:,1], normalize=True))\n",
    "        mlflow.log_metric('roc_auc_score_val', roc_auc_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('f1_score_val', f1_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('f1_score_val2', f1_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('precision_score_val', precision_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('precision_score_val2', precision_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('recall_score_val', recall_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('recall_score_val2', recall_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('brier_score', brier_score_loss(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "\n",
    "        signature = infer_signature(X_treino_new, clf.predict_proba(X_treino_new))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a otimização de hiperparâmetros anterior, nota-se que as métricas obtidas se saíram pior do que o modelo com os hiperparâmetros default. Assim como no modelo RF, será otimizado somente a quantidade de árvores, produndidade das árvores e a taxa de aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:03<01:26,  3.60s/trial, best loss: 0.26292223018277777]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:07<01:20,  3.50s/trial, best loss: 0.26063860264546723]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:10<01:16,  3.46s/trial, best loss: 0.2349608976272204] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    #test_imbalanced = [{0: len(y_treino2)/(2*np.bincount(y_treino2))[0], 1:len(y_teste2)/(2*np.bincount(y_teste2))[1]}, {0: 1, 1:1}]\n",
    "    \n",
    "    space = {\n",
    "        \"n_estimators\": hp.choice('n_estimators', np.arange(10, 500, dtype=int)),\n",
    "        \"max_depth\": hp.choice('max_depth', np.arange(10, 300, dtype=int)),\n",
    "        \"learning_rate\": hp.quniform('learning_rate', 0.0025, 0.5, 0.025)\n",
    "\n",
    "    }\n",
    "    \n",
    "    with mlflow.start_run(run_name = 'XGBoost2', experiment_id=experiment.experiment_id) as run:\n",
    "        best_params = fmin(\n",
    "            fn = partial(\n",
    "                func_objetivo,\n",
    "                expr = experiment.experiment_id,\n",
    "                modelo = 'XGB',\n",
    "                X_treino = X_treino2,\n",
    "                X_teste = X_teste2,\n",
    "                y_treino = y_treino2,\n",
    "                y_teste = y_teste2\n",
    "            ),\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 25,\n",
    "            trials = Trials(),\n",
    "            timeout = 10\n",
    "        )\n",
    "        \n",
    "        # Identificado o melhor conjunto de hiperparâmetros, treina o modelo com toda a base de treino e metrifica os escores na base de validação\n",
    "\n",
    "        clf = xgb.XGBClassifier(**best_params)\n",
    "        clf.fit(X_treino_new, y_treino)\n",
    "                   \n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('aucpr_val', average_precision_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('log_loss_val', log_loss(y_val, clf.predict_proba(X_val_new)[:,1], normalize=True))\n",
    "        mlflow.log_metric('roc_auc_score_val', roc_auc_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('f1_score_val', f1_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('f1_score_val2', f1_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('precision_score_val', precision_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('precision_score_val2', precision_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('recall_score_val', recall_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('recall_score_val2', recall_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('brier_score', brier_score_loss(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "\n",
    "        signature = infer_signature(X_treino_new, clf.predict_proba(X_treino_new))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, a otimização desconsidera a taxa de aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:03<01:29,  3.72s/trial, best loss: 0.29513599827013276]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:08<01:34,  4.10s/trial, best loss: 0.2891532969231074] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:11<01:24,  3.86s/trial, best loss: 0.2765565128189465]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/Git_GitHub/Estudo_Cartao_Credito/vCartao_Credito/lib/python3.12/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    #test_imbalanced = [{0: len(y_treino2)/(2*np.bincount(y_treino2))[0], 1:len(y_teste2)/(2*np.bincount(y_teste2))[1]}, {0: 1, 1:1}]\n",
    "    \n",
    "    space = {\n",
    "        \"n_estimators\": hp.choice('n_estimators', np.arange(10, 500, dtype=int)),\n",
    "        \"max_depth\": hp.choice('max_depth', np.arange(10, 300, dtype=int))\n",
    "\n",
    "    }\n",
    "    \n",
    "    with mlflow.start_run(run_name = 'XGBoost3', experiment_id=experiment.experiment_id) as run:\n",
    "        best_params = fmin(\n",
    "            fn = partial(\n",
    "                func_objetivo,\n",
    "                expr = experiment.experiment_id,\n",
    "                modelo = 'XGB',\n",
    "                X_treino = X_treino2,\n",
    "                X_teste = X_teste2,\n",
    "                y_treino = y_treino2,\n",
    "                y_teste = y_teste2\n",
    "            ),\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            max_evals = 25,\n",
    "            trials = Trials(),\n",
    "            timeout = 10\n",
    "        )\n",
    "        \n",
    "        # Identificado o melhor conjunto de hiperparâmetros, treina o modelo com toda a base de treino e metrifica os escores na base de validação\n",
    "\n",
    "        clf = xgb.XGBClassifier(**best_params)\n",
    "        clf.fit(X_treino_new, y_treino)\n",
    "                   \n",
    "        mlflow.log_params(clf.get_params())\n",
    "        mlflow.log_metric('aucpr_val', average_precision_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('log_loss_val', log_loss(y_val, clf.predict_proba(X_val_new)[:,1], normalize=True))\n",
    "        mlflow.log_metric('roc_auc_score_val', roc_auc_score(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "        mlflow.log_metric('f1_score_val', f1_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('f1_score_val2', f1_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('precision_score_val', precision_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('precision_score_val2', precision_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('recall_score_val', recall_score(y_val, clf.predict(X_val_new)))\n",
    "        mlflow.log_metric('recall_score_val2', recall_score(y_val, clf.predict_proba(X_val_new)[:,1] > 0.356))\n",
    "        mlflow.log_metric('brier_score', brier_score_loss(y_val, clf.predict_proba(X_val_new)[:,1]))\n",
    "\n",
    "        signature = infer_signature(X_treino_new, clf.predict_proba(X_treino_new))\n",
    "        mlflow.sklearn.log_model(clf, signature=signature, artifact_path='modelo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vCartao_Credito",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
